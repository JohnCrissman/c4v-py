{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brat Tags Data Analysis\n",
    "\n",
    "## IDs in Brat \n",
    "\n",
    "- T: text-bound annotation\n",
    "- R: relation\n",
    "- E: event\n",
    "- A: attribute\n",
    "- M: modification (alias for attribute, for backward compatibility)\n",
    "- N: normalization [new in v1.3]\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "### Annotation ID conventions\n",
    "All annotations IDs consist of a single upper-case character identifying the annotation type and a number. The initial ID characters relate to annotation types as follows:\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Entity annotations\n",
    "Each entity annotation has a unique ID and is defined by type (e.g. Person or Organization) and the span of characters containing the entity mention (represented as a \"start end\" offset pair).\n",
    "\n",
    "| ID \t| Type And Span      \t| Text     \t|\n",
    "|----\t|--------------------\t|----------\t|\n",
    "| T1 \t| Organization 0 4   \t| Sony     \t|\n",
    "| T3 \t| Organization 33 41 \t| Ericsson \t|\n",
    "| T3 \t| Country 75 81      \t| Sweden   \t|\n",
    "\n",
    "<br> \n",
    "\n",
    "#### Attribute and modification annotations\n",
    "Attribute annotations are binary or multi-valued \"flags\" that specify further aspects of other annotations. Attributes have a unique ID and are defined by reference to the ID of the annotation that the attribute marks and the attribute value.\n",
    "\n",
    "| ID \t| Type & Entity ID  \t|\n",
    "|----\t|-------------------\t|\n",
    "| A1 \t| Negation T1       \t|\n",
    "| A2 \t| Confidence T2     \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Relation annotations\n",
    "Binary relations have a unique ID and are defined by their type (e.g. Origin, Part-of) and their arguments.\n",
    "\n",
    "| ID \t| Type and Args          \t|\n",
    "|----\t|------------------------\t|\n",
    "| R1 \t| Origin Arg1:T3 Arg2:T4 \t|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Iteration\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "- Hand-picked: These tweets were handpicked if they were good examples of true public services reports or if the tweet seemed to not be a report but it really was one (confusing tweets.\n",
    "\n",
    "- Sampled: Random sample of tweets was drawn from the original dataframe. The sampling process was done apart. \n",
    "\n",
    "<br>\n",
    "\n",
    "- Hand-picked\n",
    "\n",
    "\n",
    "| id_parsed \t|          annotation_parsed \t| Count \t|\n",
    "|----------:\t|---------------------------:\t|------:\t|\n",
    "| A         \t| without-service            \t| 63    \t|\n",
    "|           \t| location                   \t| 38    \t|\n",
    "|           \t| duration                   \t| 16    \t|\n",
    "|           \t| time                       \t| 10    \t|\n",
    "|           \t| fake-information           \t| 2     \t|\n",
    "|           \t| with-service               \t| 2     \t|\n",
    "|           \t| reason                     \t| 1     \t|\n",
    "| T         \t| circumstantial-information \t| 65    \t|\n",
    "|           \t| social-report              \t| 39    \t|\n",
    "|           \t| electricity                \t| 33    \t|\n",
    "|           \t| gasoline                   \t| 25    \t|\n",
    "|           \t| water                      \t| 6     \t|\n",
    "|           \t| gas                        \t| 4     \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "- Sampled\n",
    "\n",
    "| id_parsed \t|          annotation_parsed \t| Freq \t|\n",
    "|----------:\t|---------------------------:\t|-----:\t|\n",
    "| A         \t| without-service            \t| 24   \t|\n",
    "|           \t| location                   \t| 24   \t|\n",
    "|           \t| time                       \t| 10   \t|\n",
    "|           \t| utility-company            \t| 5    \t|\n",
    "|           \t| duration                   \t| 4    \t|\n",
    "|           \t| fake-information           \t| 4    \t|\n",
    "|           \t| politician                 \t| 4    \t|\n",
    "|           \t| reason                     \t| 3    \t|\n",
    "|           \t| news-company               \t| 3    \t|\n",
    "|           \t| with-service               \t| 2    \t|\n",
    "|           \t| other                      \t| 1    \t|\n",
    "| T         \t| circumstantial-information \t| 41   \t|\n",
    "|           \t| electricity                \t| 26   \t|\n",
    "|           \t| social-report              \t| 25   \t|\n",
    "|           \t| twitter-account            \t| 12   \t|\n",
    "|           \t| gasoline                   \t| 3    \t|\n",
    "|           \t| water                      \t| 1    \t|\n",
    "|           \t| water                      \t| 1    \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:35.789545Z",
     "start_time": "2020-06-05T03:35:35.445765Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_parsed</th>\n",
       "      <th>annotation_parsed</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">A</th>\n",
       "      <th>without-service</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news-company</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake-information</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with-service</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">T</th>\n",
       "      <th>circumstantial-information</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social-report</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gasoline</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter-account</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        count\n",
       "id_parsed annotation_parsed                  \n",
       "A         without-service                  63\n",
       "          location                         38\n",
       "          duration                         16\n",
       "          time                             10\n",
       "          news-company                      4\n",
       "          fake-information                  2\n",
       "          with-service                      2\n",
       "          reason                            1\n",
       "T         circumstantial-information       65\n",
       "          social-report                    39\n",
       "          electricity                      33\n",
       "          gasoline                         25\n",
       "          water                             6\n",
       "          gas                               4\n",
       "          twitter-account                   4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "\n",
    "### Read Data\n",
    "original_df = pd.read_csv('../brat-v1.3_Crunchy_Frog/data/first-iter/balanced_dataset_brat.ann', sep = '\\t',header = None)\n",
    "\n",
    "# Rename coumns \n",
    "original_df.columns = ['id', 'annotation', 'text']\n",
    "\n",
    "# Remove the ID numbers to know if it's an entity (T) or Attribute (A)\n",
    "original_df['id_parsed'] = original_df.id.str.replace('\\d', '')\n",
    "\n",
    "# Remove text span and IDs (T & A) from column. This columns has the name of the attributes and etitites \n",
    "original_df['annotation_parsed'] = original_df.annotation.str.replace('[\\dTA]', '')\n",
    "\n",
    "\n",
    "# Remove Relation tags\n",
    "# Change Relation Id to Null\n",
    "original_df.id_parsed.replace('R', np.nan, inplace= True)\n",
    "\n",
    "# Remove nulls\n",
    "original_df.dropna(subset=['id_parsed'], inplace= True)\n",
    "\n",
    "# Group by id_parsed, annotation parsed and count results\n",
    "df = original_df[['id_parsed', 'annotation_parsed']].groupby(['id_parsed', 'annotation_parsed'], sort = True).agg({'annotation_parsed':['count']}).copy()\n",
    "\n",
    "# After the group by there's multi-index columns. We rename the columns to have the level that we want (count)\n",
    "df.columns = df.columns.levels[1]\n",
    "\n",
    "# sort_values by index. Here the trick is to also use sort_index!!\n",
    "df.sort_values('count', ascending=False)\\\n",
    "    .sort_index(level=[0], ascending=[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampled\n",
    "\n",
    "The following data was randomly sampled with the helper function ``` data_sampler.py ``` \n",
    "\n",
    "- Random_state: 58 \n",
    "- Sample: 30 \n",
    "\n",
    "` python data_sampler.py 58 30 brat-v1.3_Crunchy_Frog/data/first-iter/sampled_58_30.txt `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:36.316964Z",
     "start_time": "2020-06-05T03:35:35.792694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_parsed</th>\n",
       "      <th>annotation_parsed</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">A</th>\n",
       "      <th>without-service</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news-company</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake-information</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with-service</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">T</th>\n",
       "      <th>circumstantial-information</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social-report</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gasoline</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter-account</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        count\n",
       "id_parsed annotation_parsed                  \n",
       "A         without-service                  63\n",
       "          location                         38\n",
       "          duration                         16\n",
       "          time                             10\n",
       "          news-company                      4\n",
       "          fake-information                  2\n",
       "          with-service                      2\n",
       "          reason                            1\n",
       "T         circumstantial-information       64\n",
       "          social-report                    39\n",
       "          electricity                      33\n",
       "          gasoline                         25\n",
       "          water                             6\n",
       "          gas                               4\n",
       "          twitter-account                   4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df = pd.read_csv('tagging-set-original_for_jupyter_tagging.csv')\n",
    "\n",
    "# pd.DataFrame(complete_df.sample(30, random_state = 9).full_text)\n",
    "\n",
    "\n",
    "\n",
    "test_balance = pd.read_csv('../brat-v1.3_Crunchy_Frog/data/first-iter/balanced_dataset_brat.ann', sep = '\\t')\n",
    "\n",
    "\n",
    "# Rename coumns \n",
    "test_balance.columns = ['id', 'annotation', 'text']\n",
    "\n",
    "# Remove the ID numbers to know if it's an entity (T) or Attribute (A)\n",
    "test_balance['id_parsed'] = test_balance.id.str.replace('\\d', '')\n",
    "\n",
    "# Remove text span and IDs (T & A) from column. This columns has the name of the attributes and etitites \n",
    "test_balance['annotation_parsed'] = test_balance.annotation.str.replace('[\\dTA]', '')\n",
    "\n",
    "\n",
    "# Remove Relation tags\n",
    "# Change Relation Id to Null\n",
    "test_balance.id_parsed.replace('R', np.nan, inplace= True)\n",
    "\n",
    "# Remove nulls\n",
    "test_balance.dropna(subset=['id_parsed'], inplace= True)\n",
    "\n",
    "# Group by id_parsed, annotation parsed and count results\n",
    "df = test_balance[['id_parsed', 'annotation_parsed']].groupby(['id_parsed', 'annotation_parsed'], sort = True).agg({'annotation_parsed':['count']}).copy()\n",
    "\n",
    "# After the group by there's multi-index columns. We rename the columns to have the level that we want (count)\n",
    "df.columns = df.columns.levels[1]\n",
    "\n",
    "# sort_values by index. Here the trick is to also use sort_index!!\n",
    "df.sort_values('count', ascending=False)\\\n",
    "    .sort_index(level=[0], ascending=[True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data to input into baseline model\n",
    "\n",
    "Strategy:\n",
    "\n",
    "<br>\n",
    "\n",
    "- Volarme atributos y relations. \n",
    "- Picar dataframe en espacios, anotaicion, comienzo de span y final de span\n",
    "- Hacer Sort del Dataframe por la segunda clumna (comienzo de span)\n",
    "- Cargar el archivo original de texto, La primera columna es la posicion en el documento de inicio de la linea\n",
    "- Hacer join con el inicio de la linea. Schema - inicio de la linea y tweet. \n",
    "\n",
    "<br>\n",
    "\n",
    "Roadblock\n",
    "\n",
    "- The problem with this approach is that the text file's lines do not match with the annotation file's span. This is due that the span is for the tag, not necessarily the first word of the tweet is going to be tagged. The same is for the last tag's span vs the end of the string. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function\n",
    "\n",
    "This helper function reads brat's annotation file (.ann) and parses to a dataframe with the following schema: \n",
    "\n",
    "\n",
    "| Column            \t| Dtype  \t|\n",
    "|-------------------\t|--------\t|\n",
    "| id                \t| object \t|\n",
    "| annotation        \t| object \t|\n",
    "| text              \t| object \t|\n",
    "| id_parsed         \t| object \t|\n",
    "| annotation_parsed \t| object \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:36.330116Z",
     "start_time": "2020-06-05T03:35:36.318805Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def annotation_parser(dir_ann_file, print_grouped_annotations = False):\n",
    "    '''\n",
    "        Helper function to parse Brat's annotation file (.ann). \n",
    "            Returns a dataframe with the following schema: \n",
    "                | id                \t| object \t|\n",
    "                | annotation        \t| object \t|\n",
    "                | text              \t| object \t|\n",
    "                | id_parsed         \t| object \t|\n",
    "                | annotation_parsed \t| object \t|\n",
    "    --------------------------------------------------------------\n",
    "    \n",
    "    Params:\n",
    "        \n",
    "        dir_ann_file: String, Default = None. \n",
    "            Path to ann file.\n",
    "        \n",
    "        print_grouped_annotation: Bool. Default = False. \n",
    "            Prints count of Entities and Attributes.\n",
    "    '''\n",
    "    \n",
    "    ### Read Data\n",
    "    to_parse_df = pd.read_csv(dir_ann_file, sep = '\\t',header = None)\n",
    "\n",
    "    # Rename coumns \n",
    "    to_parse_df.columns = ['id', 'annotation', 'text']\n",
    "\n",
    "    # Remove the ID numbers to know if it's an entity (T) or Attribute (A)\n",
    "    to_parse_df['id_parsed'] = to_parse_df.id.str.replace('\\d', '')\n",
    "\n",
    "    # Remove text span and IDs (T & A) from column. This columns has the name of the attributes and etitites \n",
    "    to_parse_df['annotation_parsed'] = to_parse_df.annotation.str.replace('[\\dTA]', '')\n",
    "\n",
    "\n",
    "    # Remove Relation tags\n",
    "    # Change Relation Id to Null\n",
    "    to_parse_df.id_parsed.replace('R', np.nan, inplace= True)\n",
    "\n",
    "    # Remove nulls\n",
    "    to_parse_df.dropna(subset=['id_parsed'], inplace= True)\n",
    "\n",
    "    # Group by id_parsed, annotation parsed and count results\n",
    "    df = to_parse_df[['id_parsed', 'annotation_parsed']].groupby(['id_parsed', 'annotation_parsed'], sort = True).agg({'annotation_parsed':['count']}).copy()\n",
    "\n",
    "    # After the group by there's multi-index columns. We rename the columns to have the level that we want (count)\n",
    "    df.columns = df.columns.levels[1]\n",
    "\n",
    "    # sort_values by index. Here the trick is to also use sort_index!!\n",
    "    \n",
    "    if print_grouped_annotations == True:\n",
    "    \n",
    "        print(df.sort_values('count', ascending=False)\\\n",
    "            .sort_index(level=[0], ascending=[True]))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return to_parse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Annotations\n",
    "\n",
    "<br>\n",
    "\n",
    "- Used annotation_parser helper function to read the data. \n",
    "- Subset only Entities for simplicity sake. \n",
    "- Create span columns and store it into data frame split_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:36.392783Z",
     "start_time": "2020-06-05T03:35:36.331681Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 176 entries, 0 to 324\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Entities    176 non-null    object\n",
      " 1   first_char  176 non-null    int64 \n",
      " 2   last_char   176 non-null    int64 \n",
      " 3   text        176 non-null    object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read sampled data\n",
    "sampled_ann = annotation_parser('../brat-v1.3_Crunchy_Frog/data/first-iter/balanced_dataset_brat.ann') # 308 rows \n",
    "\n",
    "# Subset Entities and rewrite dataframe\n",
    "sampled_ann = sampled_ann[sampled_ann.id_parsed == 'T'] # 109 rows\n",
    "\n",
    "# Create span columns. Split by space.\n",
    "split_ann = sampled_ann.annotation.str.split(' ', expand = True)\n",
    "\n",
    "# Rename Columns\n",
    "split_ann.columns = ['Entities', 'first_char', 'last_char'] # It's already sorted by first_char ascending\n",
    "\n",
    "# Create new columns with each annotation's text.\n",
    "split_ann['text'] = sampled_ann.loc[sampled_ann.id_parsed == 'T', 'text']\n",
    "\n",
    "split_ann.first_char = split_ann.first_char.astype(int)\n",
    "split_ann.last_char = split_ann.last_char.astype(int)\n",
    "\n",
    "split_ann.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Text and Merge with Annotation File\n",
    "\n",
    "<br>\n",
    "\n",
    "Approach\n",
    "\n",
    "- The base strategy is to find the starting position of each new line and join it with the the first_char column in the annotation table. \n",
    "\n",
    "<br>\n",
    "\n",
    "Roadblock\n",
    "\n",
    "- The problem with this approach is that the text file's lines do not match with the annotation file's span. This is due that the span is for the tag, not necessarily the first word of the tweet is going to be tagged. The same is for the last tag's span vs the end of the string. \n",
    "\n",
    "<br>\n",
    "\n",
    "To do:\n",
    "\n",
    "- I am thinking on using fuzzy string matching to match `split_ann` text column with the original text data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:36.405726Z",
     "start_time": "2020-06-05T03:35:36.394458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Regex Module\n",
    "import re\n",
    "\n",
    "# Set max column width to none in order to read all the tweet's text. \n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "# Read text\n",
    "text = pd.read_csv('../brat-v1.3_Crunchy_Frog/data/first-iter/balanced_dataset_brat.txt', header=None )\n",
    "\n",
    "# Rename column to tweets\n",
    "text.columns = ['tweets']\n",
    "\n",
    "# Convert tweets to string\n",
    "text_string = text.tweets.to_string( header = False)\n",
    "\n",
    "# Remove extra spaces and replace them with just 1 space.\n",
    "text_string = re.sub(' +', ' ', text_string)\n",
    "\n",
    "#last_char = [pos for pos, char in enumerate(text_string) if char == '\\n']\n",
    "\n",
    "# last_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to solving the roadblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:36.457065Z",
     "start_time": "2020-06-05T03:35:36.407747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_char</th>\n",
       "      <th>last_char</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>#sinluz  terrazas  del  club  hipico      calle  bolivia  \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>113</td>\n",
       "      <td>#sinluz  valle  de  la  pascua  desde  las  7  00  am\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115</td>\n",
       "      <td>139</td>\n",
       "      <td>20  horas        #sinluz\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>141</td>\n",
       "      <td>200</td>\n",
       "      <td>hoy  toca  ramen  a  la  luz  de  una  vela  #sinluz  #lptm\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202</td>\n",
       "      <td>395</td>\n",
       "      <td>dios  si  nos  devolves  la  loooz      me  vuelvo  provida    heterosexual      catolico  apostolico  romano  y  practicamente      homofobico  y  machirulo      te  va  todo  eso      #sinluz\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>396</td>\n",
       "      <td>396</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_char  last_char  \\\n",
       "0           0         58   \n",
       "1          59         59   \n",
       "2          60        113   \n",
       "3         114        114   \n",
       "4         115        139   \n",
       "5         140        140   \n",
       "6         141        200   \n",
       "7         201        201   \n",
       "8         202        395   \n",
       "9         396        396   \n",
       "\n",
       "                                                                                                                                                                                                  text  \n",
       "0                                                                                                                                         #sinluz  terrazas  del  club  hipico      calle  bolivia  \\n  \n",
       "1                                                                                                                                                                                                   \\n  \n",
       "2                                                                                                                                              #sinluz  valle  de  la  pascua  desde  las  7  00  am\\n  \n",
       "3                                                                                                                                                                                                   \\n  \n",
       "4                                                                                                                                                                           20  horas        #sinluz\\n  \n",
       "5                                                                                                                                                                                                   \\n  \n",
       "6                                                                                                                                        hoy  toca  ramen  a  la  luz  de  una  vela  #sinluz  #lptm\\n  \n",
       "7                                                                                                                                                                                                   \\n  \n",
       "8  dios  si  nos  devolves  la  loooz      me  vuelvo  provida    heterosexual      catolico  apostolico  romano  y  practicamente      homofobico  y  machirulo      te  va  todo  eso      #sinluz\\n  \n",
       "9                                                                                                                                                                                                   \\n  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the txt as a string file\n",
    "with open('../brat-v1.3_Crunchy_Frog/data/first-iter/balanced_dataset_brat.txt') as f:\n",
    "    # only replace the break lines\n",
    "    REPLACE_br = lambda s: s.replace(\"\\n\",\"\\n\")\n",
    "    lines = map( REPLACE_br, f.readlines() )\n",
    "    \n",
    "    # save number line, length of the text and text without break lines: /n\n",
    "    # assuming one line corresponds to a single tweet\n",
    "    tuple_tweets = [(len(l), l) for l in lines if len(l) > 0]\n",
    "\n",
    "    start, end, text_ = list(), list(), list()\n",
    "    new_start = 0\n",
    "    for ttw in tuple_tweets:\n",
    "        # adds the length of the tweet\n",
    "        start.append(new_start)\n",
    "        # finds the location of the last character of the tweet\n",
    "        end.append(new_start + ttw[0] -1 )\n",
    "        text_.append(ttw[1])\n",
    "        \n",
    "        # gets the starting position of the next tweet\n",
    "        new_start = new_start + ttw[0]\n",
    "\n",
    "    text_df = pd.DataFrame({\n",
    "            \"first_char\": start,\n",
    "            \"last_char\": end,\n",
    "            \"text\": text_\n",
    "            })\n",
    "# Text - Fix de Min!!\n",
    "text_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:36.497342Z",
     "start_time": "2020-06-05T03:35:36.459607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>first_char</th>\n",
       "      <th>last_char</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>electricity</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>#sinluz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>circumstantial-information</td>\n",
       "      <td>9</td>\n",
       "      <td>56</td>\n",
       "      <td>terrazas  del  club  hipico      calle  bolivia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>electricity</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>#sinluz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>circumstantial-information</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>valle  de  la  pascua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>circumstantial-information</td>\n",
       "      <td>92</td>\n",
       "      <td>113</td>\n",
       "      <td>desde  las  7  00  am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Entities  first_char  last_char  \\\n",
       "2                 electricity           0          7   \n",
       "0  circumstantial-information           9         56   \n",
       "4                 electricity          60         67   \n",
       "6  circumstantial-information          69         90   \n",
       "8  circumstantial-information          92        113   \n",
       "\n",
       "                                              text  \n",
       "2                                          #sinluz  \n",
       "0  terrazas  del  club  hipico      calle  bolivia  \n",
       "4                                          #sinluz  \n",
       "6                            valle  de  la  pascua  \n",
       "8                            desde  las  7  00  am  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annotations DF to test \n",
    "\n",
    "split_ann = split_ann.sort_values('first_char').copy()\n",
    "split_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First attempt - Merging Text and Labels \n",
    "\n",
    "<br>\n",
    "\n",
    "This approach doesn't take into consideration tags that were made in the middle of the tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:39.356099Z",
     "start_time": "2020-06-05T03:35:36.499048Z"
    }
   },
   "outputs": [],
   "source": [
    "## This didn't work\n",
    "# pd.merge(df, split_ann, on = ['last_char'] ).info()\n",
    "\n",
    "\n",
    "text = [] # Load the matched text into a list \n",
    "ann = [] # Load the matched labels into a list\n",
    "\n",
    "# For each text_df rows and for each split_ann rows\n",
    "for index_txt, row_txt in text_df.iterrows():\n",
    "    \n",
    "    for index_ann, row_ann in split_ann.iterrows():\n",
    "    \n",
    "        # If first char of annotations and text match \n",
    "            # OR\n",
    "        # If last_char of annotations matches text \n",
    "        if row_ann[1] == row_txt[0] or row_ann[2] == row_txt[1] :\n",
    "            ann.append(row_ann[0])\n",
    "            text.append(row_txt[2])\n",
    "        else:\n",
    "            next\n",
    "\n",
    "\n",
    "txt_ann_df = pd.DataFrame({\n",
    "                    'text':text, \n",
    "                    'ann':ann\n",
    "                    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:39.363559Z",
     "start_time": "2020-06-05T03:35:39.357538Z"
    }
   },
   "outputs": [],
   "source": [
    "### Merging the txt with annotations\n",
    "\n",
    "# Create Final Dataframe\n",
    "txt_ann_df_concat = pd.concat([txt_ann_df, # Final Dataframe\n",
    "           pd.get_dummies(txt_ann_df.ann)] # Getting dummies of all annotations and append both Dfs\n",
    "          , axis = 1)\n",
    "\n",
    "# Group by each tweet's text. The tweets are duplicated from last step \n",
    "    # (if they matched both in first_char and last_char)\n",
    "\n",
    "    ## Tags are missing in this approach\n",
    "# txt_ann_df_concat.drop(['ann'], axis = 1).groupby('text', as_index = False).sum() #drop annotation column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Attempt - Merging Text and Labels\n",
    "\n",
    "This approach takes into consideration the complete span of the text. \n",
    "\n",
    "It subsets all the tags that are within the beginning of the tweet and the end of the tweet. A new column \"multi_id\" is created in order to match both dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T03:35:39.582500Z",
     "start_time": "2020-06-05T03:35:39.365712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_y</th>\n",
       "      <th>circumstantial-information</th>\n",
       "      <th>electricity</th>\n",
       "      <th>gas</th>\n",
       "      <th>gasoline</th>\n",
       "      <th>social-report</th>\n",
       "      <th>twitter-account</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#1abr  en  foto  la  fuerte  cola  que  se  registro  en  horas  de  la  magnana  en  la  bomba  de  gasolina  en  la  parroquia  #lavega  sector  #montalban  #caracas    en  el  distribuidor  la  yaguara  #singasolina    \\n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#22nov  #guayana  alta  vista    los  olivos    castillito    villa  colombia    villa  asia    villa  alianza    villa  brasil  #sinluz\\n</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#28dic  #singasolina    #ciudadguayana  deberian  ver  las  colas  aqui  haciendo  una  desde  las  6  de  la  tarde  el  viernes  27  para  equipar  el  lunes  30  ya  hay  aproximadamente  300  carros  y  sigu    \\n</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#ahora  estaciones  esperando  por  la  cisterna  en  pto  ordaz    morochas  av    atlantico    la  de  los  olivos  villa  africana    las  americas  subiendo  a  alta  vista  y  la  que  esta  frente  a  c  alta  vista  2    #singasolina  #guayana  10  28  am\\n</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#carabobo  #singasolina  imposible  salir  en  vehiculos  a  buscar  alimentos  y  agua  potable    #venezuela  tierra  de  zombies  #thewalkingdead\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                     text_y  \\\n",
       "0                                          #1abr  en  foto  la  fuerte  cola  que  se  registro  en  horas  de  la  magnana  en  la  bomba  de  gasolina  en  la  parroquia  #lavega  sector  #montalban  #caracas    en  el  distribuidor  la  yaguara  #singasolina    \\n   \n",
       "1                                                                                                                                #22nov  #guayana  alta  vista    los  olivos    castillito    villa  colombia    villa  asia    villa  alianza    villa  brasil  #sinluz\\n   \n",
       "2                                                 #28dic  #singasolina    #ciudadguayana  deberian  ver  las  colas  aqui  haciendo  una  desde  las  6  de  la  tarde  el  viernes  27  para  equipar  el  lunes  30  ya  hay  aproximadamente  300  carros  y  sigu    \\n   \n",
       "3  #ahora  estaciones  esperando  por  la  cisterna  en  pto  ordaz    morochas  av    atlantico    la  de  los  olivos  villa  africana    las  americas  subiendo  a  alta  vista  y  la  que  esta  frente  a  c  alta  vista  2    #singasolina  #guayana  10  28  am\\n   \n",
       "4                                                                                                                    #carabobo  #singasolina  imposible  salir  en  vehiculos  a  buscar  alimentos  y  agua  potable    #venezuela  tierra  de  zombies  #thewalkingdead\\n   \n",
       "\n",
       "   circumstantial-information  electricity  gas  gasoline  social-report  \\\n",
       "0                           2            0    0         2              1   \n",
       "1                           2            1    0         0              0   \n",
       "2                           4            0    0         1              2   \n",
       "3                           4            0    0         2              0   \n",
       "4                           1            0    0         1              1   \n",
       "\n",
       "   twitter-account  water  \n",
       "0                0      0  \n",
       "1                0      0  \n",
       "2                0      0  \n",
       "3                0      0  \n",
       "4                0      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize column multi_id\n",
    "split_ann['multi_id'] = 0\n",
    "\n",
    "# For each row of original text \n",
    "for i in range(text_df.shape[0]):\n",
    "    \n",
    "            # Match first character position of the annotation greater or equal to the first_char of the tweet\n",
    "            # Match last character position of the annotation less than the last character of the complete tweet\n",
    "            # This will subset the annotations on the complete span of the tweet.\n",
    "    idx = split_ann[(split_ann.first_char >= text_df.loc[i,'first_char']) &\\\n",
    "              (split_ann.first_char < text_df.loc[i,'last_char'])].index   \n",
    "\n",
    "#     Create common value for each dataframe. \n",
    "    split_ann.loc[idx, 'multi_id'] = i \n",
    "    text_df.loc[i, 'multi_id'] = i\n",
    "\n",
    "\n",
    "# Merge both dataframes and select the entities and the tweets' complete text\n",
    "merged = pd.merge(split_ann, text_df, on='multi_id').loc[:, ['Entities', 'text_y']]\n",
    "\n",
    "\n",
    "# Create dummy variables from entities (these are the tags)\n",
    "dummies = pd.get_dummies(merged.Entities)\n",
    "\n",
    "# Group by the complete text\n",
    "pd.concat([merged['text_y'], dummies], axis = 1).groupby('text_y').sum().reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function implementation\n",
    "\n",
    "The output of this helper function is intended to serve as the input for the baseline machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T01:55:24.075732Z",
     "start_time": "2020-06-11T01:55:23.397956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/diego/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>hamming_loss</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.367445</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.307870</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>BR_Bayes</td>\n",
       "      <td>BinaryRelevance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.381731</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>LP_LogisticR</td>\n",
       "      <td>LabelPowerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.381731</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>LP_SVM</td>\n",
       "      <td>LabelPowerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.391255</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.328704</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>LP_GD</td>\n",
       "      <td>LabelPowerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.405483</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>MLkNN</td>\n",
       "      <td>MLkNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.458077</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>CC_LogisticR</td>\n",
       "      <td>ClassifierChain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  hamming_loss  f1_score_micro  f1_score_macro  precision_micro  \\\n",
       "0  0.222222      0.259259        0.695652        0.367445         0.615385   \n",
       "1  0.222222      0.240741        0.723404        0.381731         0.629630   \n",
       "2  0.222222      0.240741        0.723404        0.381731         0.629630   \n",
       "3  0.222222      0.222222        0.739130        0.391255         0.653846   \n",
       "4  0.333333      0.185185        0.750000        0.405483         0.750000   \n",
       "5  0.222222      0.266667        0.739130        0.458077         0.629630   \n",
       "\n",
       "   precision_macro  recall_micro  recall_macro    model_name model_class_name  \n",
       "0         0.307870      0.800000      0.472222      BR_Bayes  BinaryRelevance  \n",
       "1         0.314815      0.850000      0.500000  LP_LogisticR    LabelPowerset  \n",
       "2         0.314815      0.850000      0.500000        LP_SVM    LabelPowerset  \n",
       "3         0.328704      0.850000      0.500000         LP_GD    LabelPowerset  \n",
       "4         0.392857      0.750000      0.448413         MLkNN            MLkNN  \n",
       "5         0.377778      0.894737      0.600000  CC_LogisticR  ClassifierChain  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import helper_functions\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../helper_functions/')\n",
    "import baseline_models\n",
    "\n",
    "test = baseline_models.report_demo(filename='../brat-v1.3_Crunchy_Frog/data/first-iter/sampled_58_30')\n",
    "\n",
    "test\n",
    "# helper_functions.annotation_merger(path_to_txt_file= '../brat-v1.3_Crunchy_Frog/data/first-iter/sampled_58_30.txt',\n",
    "#                  path_to_ann_file= '../brat-v1.3_Crunchy_Frog/data/first-iter/sampled_58_30.ann')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "704px",
    "left": "1076px",
    "top": "293px",
    "width": "367px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "362px",
    "left": "1185px",
    "right": "20px",
    "top": "129px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
