{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "\n",
    "In order to run this notebook you must have installed some packages.  See [requirements](requirements.txt).  \n",
    "File produced by running `conda list --export > requirements.txt`\n",
    "\n",
    "\n",
    "Reference: \n",
    "* [Multi-Label Text Classification by Zuzanna Deutschman](https://towardsdatascience.com/multi-label-text-classification-5c505fdedca8).\n",
    "* [Multi-label Classification Examples](https://skml.readthedocs.io/en/latest/auto_examples/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up libraries\n",
    "\n",
    "### Importing py modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# from bs4 import BeautifulSoup\n",
    "# import lxml\n",
    "\n",
    "import re\n",
    "# import csv\n",
    "# from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_new = pd.read_csv('tweets.csv')\n",
    "# tweets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets_new.copy()\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tweets.columns.values)\n",
    "\n",
    "# get the name of the columns: text and labels\n",
    "TEXT_DESCRIPTION_COL = tweets.columns.values[0]\n",
    "CIRCUMSTANTIAL_DESCRIPTION_COL = tweets.columns.values[1]\n",
    "ELECTRICITY_DESCRIPTION_COL = tweets.columns.values[2]\n",
    "GAS_DESCRIPTION_COL = tweets.columns.values[3]\n",
    "GASOLINE_DESCRIPTION_COL = tweets.columns.values[4]\n",
    "SOCIAL_DESCRIPTION_COL = tweets.columns.values[5]\n",
    "ACCOUNT_DESCRIPTION_COL = tweets.columns.values[6]\n",
    "WATER_DESCRIPTION_COL = tweets.columns.values[7]\n",
    "print('Column names:')\n",
    "print('\\t' ,TEXT_DESCRIPTION_COL)\n",
    "print('\\t' ,CIRCUMSTANTIAL_DESCRIPTION_COL)\n",
    "print('\\t' ,ELECTRICITY_DESCRIPTION_COL)\n",
    "print('\\t' ,GAS_DESCRIPTION_COL)\n",
    "print('\\t' ,GASOLINE_DESCRIPTION_COL)\n",
    "print('\\t' ,SOCIAL_DESCRIPTION_COL)\n",
    "print('\\t' ,ACCOUNT_DESCRIPTION_COL)\n",
    "print('\\t' ,WATER_DESCRIPTION_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = tweets.copy()\n",
    "\n",
    "# isolate the text and the labels\n",
    "tc_labels = tc.drop(labels=[TEXT_DESCRIPTION_COL], axis=1)\n",
    "tc_text = tc.drop(labels=[CIRCUMSTANTIAL_DESCRIPTION_COL,\n",
    "                          ELECTRICITY_DESCRIPTION_COL, GAS_DESCRIPTION_COL,\n",
    "                          GASOLINE_DESCRIPTION_COL, SOCIAL_DESCRIPTION_COL,\n",
    "                          ACCOUNT_DESCRIPTION_COL, WATER_DESCRIPTION_COL], axis=1)\n",
    "\n",
    "# replaces any number greater than 0 for a 1, bc we need \"existance\" or \"not existance\" of the\n",
    "# label on the tweet\n",
    "tc_labels = tc_labels.where(tc_labels == 0, 1)\n",
    "tc_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_tweet_labels = tc_text.merge(tc_labels, on=tc_labels.index)  # in case I need to merge them\n",
    "binarized_tweet_labels = binarized_tweet_labels.drop(labels = ['key_0'], axis=1)\n",
    "binarized_tweet_labels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data into train and test\n",
    "train, test = train_test_split(binarized_tweet_labels, random_state=42, test_size=0.30, shuffle=True)\n",
    "train_text = train[TEXT_DESCRIPTION_COL].values.astype('U')\n",
    "test_text = test[TEXT_DESCRIPTION_COL].values.astype('U')\n",
    "\n",
    "\n",
    "# creating the vectorizer, using uni-bi-tri grams, and selecting only 10000 features.\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', \n",
    "                             ngram_range=(1,3), norm='l2', max_features = 10000)\n",
    "\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)\n",
    "\n",
    "# x_train is the vectorization of each document - sparse matrix\n",
    "x_train = vectorizer.transform(train_text)\n",
    "\n",
    "# y_train are the corresponding labels of each document - pandas.DF\n",
    "y_train = train.drop(labels = [TEXT_DESCRIPTION_COL], axis=1)\n",
    "\n",
    "# same as above, but whit will be used for testing\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = [TEXT_DESCRIPTION_COL], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features selected by the vectorizer with uni-bi-tri grams\n",
    "# x_train\n",
    "features = vectorizer.get_feature_names()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model, train and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_measures(y_test, y_pred) -> None:\n",
    "\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"Hamming loss: \", hamming_loss(y_test, y_pred))\n",
    "    \n",
    "    print(\"F1 score:\")\n",
    "    print(\"\\tmicro: \", f1_score(y_test, y_pred, average='micro'))\n",
    "    print(\"\\tmacro: \", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    print(\"Precision:\")\n",
    "    print(\"\\tmicro: \", precision_score(y_test, y_pred, average='micro'))\n",
    "    print(\"\\tmacro: \", precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    print(\"Recall:\")\n",
    "    print(\"\\tmicro: \", recall_score(y_test, y_pred, average='micro'))\n",
    "    print(\"\\tmacro: \", recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Relevance\n",
    "1. with GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary Relevance: Naive Bayes with Bernoulli Distribution\n",
    "br_classifier = BinaryRelevance(BernoulliNB())\n",
    "br_classifier.fit(x_train, y_train)\n",
    "br_predictions = br_classifier.predict(x_test)\n",
    "\n",
    "report_measures(y_test, br_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Relevance: Logistic Regression\n",
    "br_classifier1 = BinaryRelevance(LogisticRegression())\n",
    "br_classifier1.fit(x_train, y_train)\n",
    "br_predictions1 = br_classifier1.predict(x_test)\n",
    "\n",
    "report_measures(y_test, br_predictions1)\n",
    "\n",
    "# br_predictions.toarray()\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Powerset\n",
    "lp_classifier = LabelPowerset(LogisticRegression())\n",
    "lp_classifier.fit(x_train, y_train)\n",
    "lp_predictions = lp_classifier.predict(x_test)\n",
    "\n",
    "report_measures(y_test, lp_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ml_classifier = MLkNN(k=4)\n",
    "# to prevent errors when handling sparse matrices.\n",
    "x_train = lil_matrix(x_train).toarray()\n",
    "y_train = lil_matrix(y_train).toarray()\n",
    "x_test = lil_matrix(x_test).toarray()\n",
    "\n",
    "ml_classifier.fit(x_train, y_train)\n",
    "ml_predictions = ml_classifier.predict(x_test)\n",
    "\n",
    "report_measures(y_test, ml_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Chain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the next classifier we need to remove from y-train, y-test categories which\n",
    "# equal 0 for all train samples\n",
    "# y_train = train.drop(labels = [TEXT_DESCRIPTION_COL], axis=1)\n",
    "# y_test = test.drop(labels = [TEXT_DESCRIPTION_COL], axis=1)\n",
    "# selected_labels = y_train.columns[y_train.sum(axis = 0, skipna = True) > 0].tolist()\n",
    "\n",
    "# y_train = y_train.filter(selected_labels, axis=1)\n",
    "# y_test = y_test.filter(selected_labels, axis=1)\n",
    "# x_train = vectorizer.transform(train_text)\n",
    "# x_test = vectorizer.transform(test_text)\n",
    "\n",
    "cc_classifier = ClassifierChain(LogisticRegression())\n",
    "cc_classifier.fit(x_train, y_train)\n",
    "# print(cc_classifier.predict(x_test))\n",
    "cc_predictions_proba = cc_classifier.predict_proba(x_test)\n",
    "\n",
    "report_measures(y_test, cc_classifier.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting metrics as a function of threashold\n",
    "def plotting_metrics_function_of_threshold(model_name, cc_predictions_proba, y_test):\n",
    "    th = []\n",
    "    f = []\n",
    "    ham = []\n",
    "    ac = []\n",
    "\n",
    "    for t in range (5,90): # threshold value\n",
    "        y_pred_new = (cc_predictions_proba >= t/100).astype(int)\n",
    "        print(\"t =\" ,t/100, '\\t', \"Accuracy = \",accuracy_score(y_test,y_pred_new),\n",
    "             '\\t', \"F1 = \",f1_score(y_test,y_pred_new, average=\"micro\"), '\\t',\n",
    "              \"Hamming loss = \",hamming_loss(y_test,y_pred_new))\n",
    "        th.append(t)\n",
    "        ac.append(accuracy_score(y_test,y_pred_new))\n",
    "        f.append(f1_score(y_test,y_pred_new, average=\"micro\"))\n",
    "        ham.append(hamming_loss(y_test,y_pred_new))\n",
    "    plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "    with plt.style.context('ggplot'):\n",
    "        plt.plot(th, f)\n",
    "        plt.plot(th, ham)\n",
    "        plt.plot(th, ac)\n",
    "        plt.legend(['F1', 'Hamming loss', 'Accuracy'], loc='center left', fontsize = 14)\n",
    "        plt.ylabel(\"metrics\", fontsize = 14)\n",
    "        plt.xlabel(\"threshold\", fontsize = 14)\n",
    "        plt.title(model_name, fontsize = 18)\n",
    "    plt.show()\n",
    "    \n",
    "plotting_metrics_function_of_threshold('Chain Model Classifier', cc_predictions_proba, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi label Classifier using Neural Networks\n",
    "\n",
    "Two ways to do this:\n",
    "* using TF-IDF Vectorizer\n",
    "* using Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using TF-IDF vectorizer\n",
    "For this model we will use TF-IDF vectorizer generated on [Section 1.3](#Vectorizing) to convert the sentences into vectors, then this will be passed\n",
    "into the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train.shape[1])\n",
    "# x_train\n",
    "# y_train\n",
    "# x_test\n",
    "# y_test\n",
    "\n",
    "# work to be done. . .\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, input_dim=x_train.shape[1], activation=\"relu\"))\n",
    "# model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(tweets.columns.values.shape[0] -1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "batch_size = 20\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size, epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "results = model.evaluate(x_test, y_test, batch_size)\n",
    "\n",
    "nn_predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(history)\n",
    "print(results)\n",
    "# nn_predictions\n",
    "# plotting_metrics_function_of_threshold('ANN Classifier', nn_predictions, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pred_prob = pd.DataFrame(nn_predictions, columns = tweets.columns.values[1:])\n",
    "pd_pred = (pd_pred_prob.copy() >= 0.5)\n",
    "pd_pred = pd_pred.where(pd_pred == True, 0)\n",
    "pd_pred = pd_pred.where(pd_pred == False, 1)\n",
    "\n",
    "report_measures(y_test, pd_pred.to_numpy(dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_pred.insert(0, 'tweet', test_text)\n",
    "# pd_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_doc = 'La cosa esta dificil con lo de la luz y todo lo demas'\n",
    "tw_doc_vector = vectorizer.transform([tw_doc])\n",
    "\n",
    "tw_pred = model.predict([tw_doc_vector])\n",
    "print('Prediction: \\n', tw_doc)\n",
    "pd.DataFrame(tw_pred, columns = tweets.columns.values[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using Word Embeddings\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarized_tweet_labels\n",
    "\n",
    "#  these are all the labels, for now I will select only one of them\n",
    "#  and we will test the classification on a single label.\n",
    "\n",
    "# print( TEXT_DESCRIPTION_COL )\n",
    "# print( CIRCUMSTANTIAL_DESCRIPTION_COL )\n",
    "# print( ELECTRICITY_DESCRIPTION_COL )\n",
    "# print( GAS_DESCRIPTION_COL )\n",
    "# print( GASOLINE_DESCRIPTION_COL )\n",
    "# print( SOCIAL_DESCRIPTION_COL )\n",
    "# print( ACCOUNT_DESCRIPTION_COL )\n",
    "# print( WATER_DESCRIPTION_COL )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
